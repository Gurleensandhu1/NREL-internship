Failure # 1 (occurred at 2021-06-24_23-39-54)
Traceback (most recent call last):
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 426, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 378, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/worker.py", line 1457, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OSError): [36mray::PPO.train()[39m (pid=65858, ip=10.148.1.19)
  File "python/ray/_raylet.pyx", line 636, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 619, in ray._raylet.execute_task.function_executor
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 444, in train
    raise e
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 433, in train
    result = Trainable.train(self)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/tune/trainable.py", line 176, in train
    result = self._train()
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 129, in _train
    fetches = self.optimizer.step()
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/optimizers/multi_gpu_optimizer.py", line 140, in step
    self.num_envs_per_worker, self.train_batch_size)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/optimizers/rollout.py", line 29, in collect_samples
    next_sample = ray_get_and_free(fut_sample)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/utils/memory.py", line 33, in ray_get_and_free
    result = ray.get(object_ids)
ray.exceptions.RayTaskError(OSError): [36mray::RolloutWorker.sample()[39m (pid=65844, ip=10.148.1.19)
  File "python/ray/_raylet.pyx", line 636, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 619, in ray._raylet.execute_task.function_executor
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 471, in sample
    batches = [self.input_reader.next()]
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py", line 56, in next
    batches = [self.get_data()]
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py", line 99, in get_data
    item = next(self.rollout_provider)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py", line 319, in _env_runner
    soft_horizon, no_done_at_end)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py", line 480, in _process_observations
    resetted_obs = base_env.try_reset(env_id)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/env/base_env.py", line 336, in try_reset
    return {_DUMMY_AGENT_ID: self.vector_env.reset_at(env_id)}
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/env/vector_env.py", line 104, in reset_at
    return self.envs[index].reset()
  File "/lustre/eaglefs/projects/cavs/mlunacek/flow_work/cavs-central-control/refactor/configs/merge/environment.py", line 369, in reset
    return super().reset()
  File "/lustre/eaglefs/projects/cavs/mlunacek/flow_work/flow/flow/envs/base.py", line 465, in reset
    self.restart_simulation(self.sim_params)
  File "/lustre/eaglefs/projects/cavs/mlunacek/flow_work/flow/flow/envs/base.py", line 248, in restart_simulation
    self.k.close()
  File "/lustre/eaglefs/projects/cavs/mlunacek/flow_work/flow/flow/core/kernel/kernel.py", line 109, in close
    self.simulation.close()
  File "/lustre/eaglefs/projects/cavs/mlunacek/flow_work/flow/flow/core/kernel/simulation/traci.py", line 149, in close
    self.save_emission()
  File "/lustre/eaglefs/projects/cavs/mlunacek/flow_work/flow/flow/core/kernel/simulation/traci.py", line 323, in save_emission
    print(os.path.join(self.emission_path, name), self.emission_path)
OSError: [Errno 28] No space left on device

Failure # 2 (occurred at 2021-06-24_23-41-24)
Traceback (most recent call last):
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 426, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 378, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/worker.py", line 1457, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OSError): [36mray::PPO.train()[39m (pid=65858, ip=10.148.1.19)
  File "python/ray/_raylet.pyx", line 636, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 619, in ray._raylet.execute_task.function_executor
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 444, in train
    raise e
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 433, in train
    result = Trainable.train(self)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/tune/trainable.py", line 176, in train
    result = self._train()
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 129, in _train
    fetches = self.optimizer.step()
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/optimizers/multi_gpu_optimizer.py", line 140, in step
    self.num_envs_per_worker, self.train_batch_size)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/optimizers/rollout.py", line 29, in collect_samples
    next_sample = ray_get_and_free(fut_sample)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/utils/memory.py", line 33, in ray_get_and_free
    result = ray.get(object_ids)
ray.exceptions.RayTaskError(OSError): [36mray::RolloutWorker.sample()[39m (pid=65844, ip=10.148.1.19)
  File "python/ray/_raylet.pyx", line 636, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 619, in ray._raylet.execute_task.function_executor
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 471, in sample
    batches = [self.input_reader.next()]
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py", line 56, in next
    batches = [self.get_data()]
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py", line 99, in get_data
    item = next(self.rollout_provider)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py", line 319, in _env_runner
    soft_horizon, no_done_at_end)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py", line 480, in _process_observations
    resetted_obs = base_env.try_reset(env_id)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/env/base_env.py", line 336, in try_reset
    return {_DUMMY_AGENT_ID: self.vector_env.reset_at(env_id)}
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/rllib/env/vector_env.py", line 104, in reset_at
    return self.envs[index].reset()
  File "/lustre/eaglefs/projects/cavs/mlunacek/flow_work/cavs-central-control/refactor/configs/merge/environment.py", line 369, in reset
    return super().reset()
  File "/lustre/eaglefs/projects/cavs/mlunacek/flow_work/flow/flow/envs/base.py", line 465, in reset
    self.restart_simulation(self.sim_params)
  File "/lustre/eaglefs/projects/cavs/mlunacek/flow_work/flow/flow/envs/base.py", line 248, in restart_simulation
    self.k.close()
  File "/lustre/eaglefs/projects/cavs/mlunacek/flow_work/flow/flow/core/kernel/kernel.py", line 109, in close
    self.simulation.close()
  File "/lustre/eaglefs/projects/cavs/mlunacek/flow_work/flow/flow/core/kernel/simulation/traci.py", line 149, in close
    self.save_emission()
  File "/lustre/eaglefs/projects/cavs/mlunacek/flow_work/flow/flow/core/kernel/simulation/traci.py", line 323, in save_emission
    print(os.path.join(self.emission_path, name), self.emission_path)
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 222, in start_trial
    self._start_trial(trial, checkpoint, remote_runner)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 156, in _start_trial
    self.restore(trial, checkpoint)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 608, in restore
    DEFAULT_GET_TIMEOUT)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/worker.py", line 1450, in get
    values = worker.get_objects(object_ids, timeout=timeout)
  File "/projects/aces/mlunacek/condaenvs/flow/lib/python3.7/site-packages/ray/worker.py", line 318, in get_objects
    object_ids, self.current_task_id, timeout_ms)
  File "python/ray/_raylet.pyx", line 815, in ray._raylet.CoreWorker.get_objects
  File "python/ray/_raylet.pyx", line 169, in ray._raylet.check_status
ray.exceptions.RayTimeoutError: Get timed out: some object(s) not ready.

